{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Step 1: Setup and Imports ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import hopsworks\n",
    "import exclude.key\n",
    "import os\n",
    "\n",
    "# Hopsworks\n",
    "# HOPSWORKS_API_KEY = exclude.key.HOPSWORKS_API_KEY\n",
    "FEATURE_GROUP_NAME = \"bars_near_london_bridge\"\n",
    "FEATURE_GROUP_VERSION = 1\n",
    "FEATURE_VIEW_VERSION = 1\n",
    "\n",
    "# Connect to Hopsworks\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()\n",
    "mr = project.get_model_registry()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Step 2: Load Data from the Feature group ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups.\n",
    "fg = fs.get_feature_group(\n",
    "    name=FEATURE_GROUP_NAME, \n",
    "    version=FEATURE_GROUP_VERSION,\n",
    ")\n",
    "\n",
    "# Select features for training datasets\n",
    "df = fg.read()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Step 3: Process the Data ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transformation functions from the feature store\n",
    "min_max_scaler = fs.get_transformation_function(name=\"min_max_scaler\")\n",
    "label_encoder = fs.get_transformation_function(name=\"label_encoder\")\n",
    "\n",
    "# Define numerical and categorical features\n",
    "numerical_features = [\"hour\"]\n",
    "categorical_features = [\"day\"]\n",
    "\n",
    "# Map features to transformation functions\n",
    "transformation_functions = {}\n",
    "for feature in numerical_features:\n",
    "    transformation_functions[feature] = min_max_scaler\n",
    "for feature in categorical_features:\n",
    "    transformation_functions[feature] = label_encoder\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Step 4: Create the feature view ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = fg.select_except(['busyness','venue_address','venue_name','last_updated','busyness'])\n",
    "\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name='busyness_feature_view',\n",
    "    version=FEATURE_VIEW_VERSION,\n",
    "    query=query,\n",
    "    labels=[\"busyness_numeric\"],\n",
    "    transformation_functions=transformation_functions,\n",
    ")\n",
    "\n",
    "# if the featureview is already created just retrieve it \n",
    "feature_view = fs.get_feature_view(name='busyness_feature_view', version=FEATURE_VIEW_VERSION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Step 5: Create the training dataset ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation, and test sets\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = feature_view.train_validation_test_split(\n",
    "    validation_size=0.2,\n",
    "    test_size=0.1,\n",
    ")\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Step 6: Train and evaluate the model ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Create an instance of the XGBClassifier\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='f1_macro', cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters from GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_model = xgb.XGBClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "y_pred_val = best_model.predict(X_val)\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "# Compute metrics\n",
    "metrics = {\"f1_score\": f1_score(y_test, y_pred_test, average='macro')}\n",
    "print(metrics)\n",
    "\n",
    "# Confusion matrix\n",
    "results = confusion_matrix(y_test, y_pred_test, labels=[0, 1])\n",
    "df_cm = pd.DataFrame(results, ['True Low', 'True High'], ['Pred Low', 'Pred High'])\n",
    "cm = sns.heatmap(df_cm, annot=True)\n",
    "cm.get_figure().show()\n",
    "fig = cm.get_figure()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Step 7: Save the model ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "import joblib\n",
    "\n",
    "# Create a Schema for the input features\n",
    "input_schema = Schema(X_train)\n",
    "\n",
    "# Create a Schema for the output labels\n",
    "output_schema = Schema(y_train)\n",
    "\n",
    "# Create a ModelSchema using the input and output schemas\n",
    "model_schema = ModelSchema(\n",
    "    input_schema=input_schema, \n",
    "    output_schema=output_schema,\n",
    ")\n",
    "\n",
    "# Convert the ModelSchema to a dictionary representation\n",
    "model_schema.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory name for the model registry\n",
    "model_dir = \"busyness_model\"\n",
    "\n",
    "# Check if the directory exists, and create it if not\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "# Save the trained XGBoost model to a file within the model directory\n",
    "joblib.dump(model, f\"{model_dir}/xgboost_busyness.pkl\")\n",
    "\n",
    "# Save the confusion matrix plot to an image file within the model directory\n",
    "fig.savefig(f\"{model_dir}/confusion_matrix.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model registry\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# Create a Python model in the model registry\n",
    "busyness_model = mr.python.create_model(\n",
    "    name=\"xgboost_busyness\", \n",
    "    metrics=metrics,                     # Specify the metrics used to evaluate the model\n",
    "    model_schema=model_schema,           # Provide the model schema\n",
    "    description=\"Busyness Model\",# Add a description for the model\n",
    ")\n",
    "\n",
    "# Save the model to the specified model directory\n",
    "busyness_model.save(model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
